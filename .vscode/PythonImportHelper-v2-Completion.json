[
    {
        "label": "*",
        "importPath": "llm_selector_package.llm_selector",
        "description": "llm_selector_package.llm_selector",
        "isExtraImport": true,
        "detail": "llm_selector_package.llm_selector",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "llm_selector_package.llm_selector",
        "description": "llm_selector_package.llm_selector",
        "isExtraImport": true,
        "detail": "llm_selector_package.llm_selector",
        "documentation": {}
    },
    {
        "label": "ModelConfigurator",
        "importPath": "llm_selector_package.model_setup",
        "description": "llm_selector_package.model_setup",
        "isExtraImport": true,
        "detail": "llm_selector_package.model_setup",
        "documentation": {}
    },
    {
        "label": "ModelConfigurator",
        "importPath": "llm_selector_package.model_setup",
        "description": "llm_selector_package.model_setup",
        "isExtraImport": true,
        "detail": "llm_selector_package.model_setup",
        "documentation": {}
    },
    {
        "label": "Console",
        "importPath": "rich.console",
        "description": "rich.console",
        "isExtraImport": true,
        "detail": "rich.console",
        "documentation": {}
    },
    {
        "label": "Console",
        "importPath": "rich.console",
        "description": "rich.console",
        "isExtraImport": true,
        "detail": "rich.console",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "print",
        "importPath": "rich",
        "description": "rich",
        "isExtraImport": true,
        "detail": "rich",
        "documentation": {}
    },
    {
        "label": "print",
        "importPath": "rich",
        "description": "rich",
        "isExtraImport": true,
        "detail": "rich",
        "documentation": {}
    },
    {
        "label": "print",
        "importPath": "rich",
        "description": "rich",
        "isExtraImport": true,
        "detail": "rich",
        "documentation": {}
    },
    {
        "label": "pdb",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pdb",
        "description": "pdb",
        "detail": "pdb",
        "documentation": {}
    },
    {
        "label": "PromptTemplate",
        "importPath": "langchain.prompts",
        "description": "langchain.prompts",
        "isExtraImport": true,
        "detail": "langchain.prompts",
        "documentation": {}
    },
    {
        "label": "JsonOutputParser",
        "importPath": "langchain_core.output_parsers",
        "description": "langchain_core.output_parsers",
        "isExtraImport": true,
        "detail": "langchain_core.output_parsers",
        "documentation": {}
    },
    {
        "label": "ChatOllama",
        "importPath": "langchain_community.chat_models",
        "description": "langchain_community.chat_models",
        "isExtraImport": true,
        "detail": "langchain_community.chat_models",
        "documentation": {}
    },
    {
        "label": "OpenAI",
        "importPath": "openai",
        "description": "openai",
        "isExtraImport": true,
        "detail": "openai",
        "documentation": {}
    },
    {
        "label": "Groq",
        "importPath": "groq",
        "description": "groq",
        "isExtraImport": true,
        "detail": "groq",
        "documentation": {}
    },
    {
        "label": "importlib.util",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib.util",
        "description": "importlib.util",
        "detail": "importlib.util",
        "documentation": {}
    },
    {
        "label": "sample_to_use_menu_and_model_activation",
        "kind": 5,
        "importPath": "common_modules.all_in_one_module",
        "description": "common_modules.all_in_one_module",
        "peekOfCode": "sample_to_use_menu_and_model_activation = \"\"\"\nselector = LLMSelector(model_choices)\nreturn_val = selector.run()\nconfigurator = ModelConfigurator(return_val)\nconfigurator.configure()\n\"\"\"",
        "detail": "common_modules.all_in_one_module",
        "documentation": {}
    },
    {
        "label": "selector",
        "kind": 5,
        "importPath": "common_modules.all_in_one_module",
        "description": "common_modules.all_in_one_module",
        "peekOfCode": "selector = LLMSelector(model_choices)\nreturn_val = selector.run()\nconfigurator = ModelConfigurator(return_val)\nconfigurator.configure()\n\"\"\"",
        "detail": "common_modules.all_in_one_module",
        "documentation": {}
    },
    {
        "label": "return_val",
        "kind": 5,
        "importPath": "common_modules.all_in_one_module",
        "description": "common_modules.all_in_one_module",
        "peekOfCode": "return_val = selector.run()\nconfigurator = ModelConfigurator(return_val)\nconfigurator.configure()\n\"\"\"",
        "detail": "common_modules.all_in_one_module",
        "documentation": {}
    },
    {
        "label": "configurator",
        "kind": 5,
        "importPath": "common_modules.all_in_one_module",
        "description": "common_modules.all_in_one_module",
        "peekOfCode": "configurator = ModelConfigurator(return_val)\nconfigurator.configure()\n\"\"\"",
        "detail": "common_modules.all_in_one_module",
        "documentation": {}
    },
    {
        "label": "LLMSelector",
        "kind": 6,
        "importPath": "llm_selector_package.llm_selector",
        "description": "llm_selector_package.llm_selector",
        "peekOfCode": "class LLMSelector:\n    def __init__(self, models):\n        self.models = models\n        self.console = Console()\n    def make_better_prompt(self, prompt_msg):\n        # Defining LLM\n        local_llm = \"llama3\"\n        # llama3 = ChatOllama(model=local_llm, temperature=0)\n        llama3_json = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n        query_prompt = PromptTemplate(",
        "detail": "llm_selector_package.llm_selector",
        "documentation": {}
    },
    {
        "label": "getch",
        "kind": 2,
        "importPath": "llm_selector_package.llm_selector",
        "description": "llm_selector_package.llm_selector",
        "peekOfCode": "def getch():\n    if sys.platform.startswith(\"win\"):\n        import msvcrt\n        return msvcrt.getch().decode(\"utf-8\")\n    else:\n        import tty, termios\n        fd = sys.stdin.fileno()\n        old_settings = termios.tcgetattr(fd)\n        try:\n            tty.setraw(fd)",
        "detail": "llm_selector_package.llm_selector",
        "documentation": {}
    },
    {
        "label": "model_choices",
        "kind": 5,
        "importPath": "llm_selector_package.llm_selector",
        "description": "llm_selector_package.llm_selector",
        "peekOfCode": "model_choices = {\n    \"0\": \"Clear all Environment\",\n    \"1\": \"GROQ\",\n    \"2\": \"gpt-3.5-turbo-1106\",\n    \"3\": \"gpt-4.0\",\n    \"4\": \"mistral\",\n    \"5\": \"LM Studio\",\n    \"6\": \"Other\",\n    \"Q\": \"QUIT\",\n}",
        "detail": "llm_selector_package.llm_selector",
        "documentation": {}
    },
    {
        "label": "ModelConfigurator",
        "kind": 6,
        "importPath": "llm_selector_package.model_setup",
        "description": "llm_selector_package.model_setup",
        "peekOfCode": "class ModelConfigurator:\n    _instance = None\n    all_env = {}  # new public variable\n    client = None\n    def __new__(cls, model_choice):\n        if cls._instance is None:\n            cls._instance = super().__new__(cls)\n        return cls._instance\n    def __init__(self, model_choice):\n        if not hasattr(self, \"model_choice\"):",
        "detail": "llm_selector_package.model_setup",
        "documentation": {}
    },
    {
        "label": "CustomEncoder",
        "kind": 6,
        "importPath": "llm_selector_package.python_code_error_function_calling",
        "description": "llm_selector_package.python_code_error_function_calling",
        "peekOfCode": "class CustomEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, ModuleNotFoundError):\n            return str(obj)\n        return super().default(obj)\ntools = [\n            {\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": \"check_package\",",
        "detail": "llm_selector_package.python_code_error_function_calling",
        "documentation": {}
    },
    {
        "label": "ConversationManager",
        "kind": 6,
        "importPath": "llm_selector_package.python_code_error_function_calling",
        "description": "llm_selector_package.python_code_error_function_calling",
        "peekOfCode": "class ConversationManager:\n    def __init__(self, api_key, model_name):\n        self.client = Groq(api_key=api_key)\n        self.MODEL = model_name # \"llama3-70b-8192\"\n    # @classmethod\n    def check_package(self, package_name):\n        spec = importlib.util.find_spec(package_name)\n        if spec is None:\n            return json.dumps(\n                {",
        "detail": "llm_selector_package.python_code_error_function_calling",
        "documentation": {}
    },
    {
        "label": "error_val",
        "kind": 5,
        "importPath": "llm_selector_package.python_code_error_function_calling",
        "description": "llm_selector_package.python_code_error_function_calling",
        "peekOfCode": "error_val = \"\" \nclass CustomEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, ModuleNotFoundError):\n            return str(obj)\n        return super().default(obj)\ntools = [\n            {\n                \"type\": \"function\",\n                \"function\": {",
        "detail": "llm_selector_package.python_code_error_function_calling",
        "documentation": {}
    },
    {
        "label": "tools",
        "kind": 5,
        "importPath": "llm_selector_package.python_code_error_function_calling",
        "description": "llm_selector_package.python_code_error_function_calling",
        "peekOfCode": "tools = [\n            {\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": \"check_package\",\n                    \"description\": \"Check if the given python package is installed for the given package name\",\n                    \"parameters\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"package_name\": {",
        "detail": "llm_selector_package.python_code_error_function_calling",
        "documentation": {}
    },
    {
        "label": "dummy_value",
        "kind": 5,
        "importPath": "llm_selector_package.testing_python",
        "description": "llm_selector_package.testing_python",
        "peekOfCode": "dummy_value = \"yahoooooo\"",
        "detail": "llm_selector_package.testing_python",
        "documentation": {}
    },
    {
        "label": "temp",
        "kind": 5,
        "importPath": "new_model_123.variables",
        "description": "new_model_123.variables",
        "peekOfCode": "temp = \"this is temp variable\"",
        "detail": "new_model_123.variables",
        "documentation": {}
    }
]